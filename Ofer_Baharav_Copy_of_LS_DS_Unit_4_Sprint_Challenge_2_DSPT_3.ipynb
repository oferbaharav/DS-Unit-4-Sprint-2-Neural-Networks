{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S2-NNF-DS10",
      "language": "python",
      "name": "u4-s2-nnf-ds10"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.22.4"
    },
    "colab": {
      "name": "Ofer_Baharav_Copy of LS_DS_Unit_4_Sprint_Challenge_2_DSPT_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oferbaharav/DS-Unit-4-Sprint-2-Neural-Networks/blob/master/Ofer_Baharav_Copy_of_LS_DS_Unit_4_Sprint_Challenge_2_DSPT_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU5ckW4s2A-N",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2*\n",
        "\n",
        "# Sprint Challenge - Neural Network Foundations\n",
        "\n",
        "Table of Problems\n",
        "\n",
        "1. [Defining Neural Networks](#Q1)\n",
        "2. [Simple Perceptron](#Q2)\n",
        "    - Perceptron\n",
        "    - Multilayer Perceptron\n",
        "    - Analyze and Compare\n",
        "4. [Keras MMP](#Q3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDxLIny42A-O",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"Q1\"></a>\n",
        "## 1. Defining Neural Networks \n",
        "\n",
        "Write *your own* definitions for the following terms:\n",
        "\n",
        "- **Neuron:**\n",
        "- **Input Layer:**\n",
        "- **Hidden Layer:**\n",
        "- **Output Layer:**\n",
        "- **Activation Function:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sPNIHR82A-P",
        "colab_type": "text"
      },
      "source": [
        "Explain how back propagation works as if you were explaining it to a five year-old. Use your own words, but feel free to reference external materials for this question. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_W0Jmdk2A-Q",
        "colab_type": "text"
      },
      "source": [
        "# Your Answer Here - Change the Cell to Markdown\n",
        "\n",
        "* Neuron: a unit capable of logic such as takes weighted inputs, applies \n",
        "activation, and returns an output\n",
        "* Input Layer: this is the layer that holds the data that the model will train on. Neurons here accept input from the dataset (like dog, cat)\n",
        "* Hidden Layer: this layer (or layers) sits between the input and output layers and aplies activation function then passes the results\n",
        "* Output Layer: last layer that receives input from previous layer, might also have an activation function, returns an output that is the model's prediction\n",
        "* Activation Function: functions that model non linear relationships like sigmoid and relu\n",
        "* Backpropagation to a 5 year old: making a computer program learn from mistakes and getting better at doing something with training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IR1oMGZ2A-V",
        "colab_type": "text"
      },
      "source": [
        "Remember our Simple Perceptron Class from Monday. In a simple prediction describe the process of making a prediction. How do you go from inputs to predicted output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4pLoWy72A-W",
        "colab_type": "text"
      },
      "source": [
        "# Your Answer Here - Change the Cell to Markdown\n",
        "* You take an inputs, you multiply those by weights, sum the inputs * weights, and get output as the prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-R0llfK2A-Z",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"Q2\"></a>\n",
        "## 2. Simple Perceptron\n",
        "\n",
        "In this question, you will build two neural networks using Tensorflow Keras. After you build these two models, compare the results of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-9Pv_Lg2A-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Our Dataset\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "xx, yy = np.meshgrid(np.linspace(-3, 3, 50),\n",
        "                     np.linspace(-3, 3, 50))\n",
        "rng = np.random.RandomState(0)\n",
        "\n",
        "\"Use this X & y in the following 2 models\"\n",
        "X = rng.randn(300, 2)\n",
        "y = np.array(np.logical_xor(X[:, 0] > 0, X[:, 1] > 0), \n",
        "             dtype=int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JKOC6KA8vwH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc563674-7f3d-4f3c-cf6a-68b7d5b0dc3f"
      },
      "source": [
        "X"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.76405235,  0.40015721],\n",
              "       [ 0.97873798,  2.2408932 ],\n",
              "       [ 1.86755799, -0.97727788],\n",
              "       [ 0.95008842, -0.15135721],\n",
              "       [-0.10321885,  0.4105985 ],\n",
              "       [ 0.14404357,  1.45427351],\n",
              "       [ 0.76103773,  0.12167502],\n",
              "       [ 0.44386323,  0.33367433],\n",
              "       [ 1.49407907, -0.20515826],\n",
              "       [ 0.3130677 , -0.85409574],\n",
              "       [-2.55298982,  0.6536186 ],\n",
              "       [ 0.8644362 , -0.74216502],\n",
              "       [ 2.26975462, -1.45436567],\n",
              "       [ 0.04575852, -0.18718385],\n",
              "       [ 1.53277921,  1.46935877],\n",
              "       [ 0.15494743,  0.37816252],\n",
              "       [-0.88778575, -1.98079647],\n",
              "       [-0.34791215,  0.15634897],\n",
              "       [ 1.23029068,  1.20237985],\n",
              "       [-0.38732682, -0.30230275],\n",
              "       [-1.04855297, -1.42001794],\n",
              "       [-1.70627019,  1.9507754 ],\n",
              "       [-0.50965218, -0.4380743 ],\n",
              "       [-1.25279536,  0.77749036],\n",
              "       [-1.61389785, -0.21274028],\n",
              "       [-0.89546656,  0.3869025 ],\n",
              "       [-0.51080514, -1.18063218],\n",
              "       [-0.02818223,  0.42833187],\n",
              "       [ 0.06651722,  0.3024719 ],\n",
              "       [-0.63432209, -0.36274117],\n",
              "       [-0.67246045, -0.35955316],\n",
              "       [-0.81314628, -1.7262826 ],\n",
              "       [ 0.17742614, -0.40178094],\n",
              "       [-1.63019835,  0.46278226],\n",
              "       [-0.90729836,  0.0519454 ],\n",
              "       [ 0.72909056,  0.12898291],\n",
              "       [ 1.13940068, -1.23482582],\n",
              "       [ 0.40234164, -0.68481009],\n",
              "       [-0.87079715, -0.57884966],\n",
              "       [-0.31155253,  0.05616534],\n",
              "       [-1.16514984,  0.90082649],\n",
              "       [ 0.46566244, -1.53624369],\n",
              "       [ 1.48825219,  1.89588918],\n",
              "       [ 1.17877957, -0.17992484],\n",
              "       [-1.07075262,  1.05445173],\n",
              "       [-0.40317695,  1.22244507],\n",
              "       [ 0.20827498,  0.97663904],\n",
              "       [ 0.3563664 ,  0.70657317],\n",
              "       [ 0.01050002,  1.78587049],\n",
              "       [ 0.12691209,  0.40198936],\n",
              "       [ 1.8831507 , -1.34775906],\n",
              "       [-1.270485  ,  0.96939671],\n",
              "       [-1.17312341,  1.94362119],\n",
              "       [-0.41361898, -0.74745481],\n",
              "       [ 1.92294203,  1.48051479],\n",
              "       [ 1.86755896,  0.90604466],\n",
              "       [-0.86122569,  1.91006495],\n",
              "       [-0.26800337,  0.8024564 ],\n",
              "       [ 0.94725197, -0.15501009],\n",
              "       [ 0.61407937,  0.92220667],\n",
              "       [ 0.37642553, -1.09940079],\n",
              "       [ 0.29823817,  1.3263859 ],\n",
              "       [-0.69456786, -0.14963454],\n",
              "       [-0.43515355,  1.84926373],\n",
              "       [ 0.67229476,  0.40746184],\n",
              "       [-0.76991607,  0.53924919],\n",
              "       [-0.67433266,  0.03183056],\n",
              "       [-0.63584608,  0.67643329],\n",
              "       [ 0.57659082, -0.20829876],\n",
              "       [ 0.39600671, -1.09306151],\n",
              "       [-1.49125759,  0.4393917 ],\n",
              "       [ 0.1666735 ,  0.63503144],\n",
              "       [ 2.38314477,  0.94447949],\n",
              "       [-0.91282223,  1.11701629],\n",
              "       [-1.31590741, -0.4615846 ],\n",
              "       [-0.06824161,  1.71334272],\n",
              "       [-0.74475482, -0.82643854],\n",
              "       [-0.09845252, -0.66347829],\n",
              "       [ 1.12663592, -1.07993151],\n",
              "       [-1.14746865, -0.43782004],\n",
              "       [-0.49803245,  1.92953205],\n",
              "       [ 0.94942081,  0.08755124],\n",
              "       [-1.22543552,  0.84436298],\n",
              "       [-1.00021535, -1.5447711 ],\n",
              "       [ 1.18802979,  0.31694261],\n",
              "       [ 0.92085882,  0.31872765],\n",
              "       [ 0.85683061, -0.65102559],\n",
              "       [-1.03424284,  0.68159452],\n",
              "       [-0.80340966, -0.68954978],\n",
              "       [-0.4555325 ,  0.01747916],\n",
              "       [-0.35399391, -1.37495129],\n",
              "       [-0.6436184 , -2.22340315],\n",
              "       [ 0.62523145, -1.60205766],\n",
              "       [-1.10438334,  0.05216508],\n",
              "       [-0.739563  ,  1.5430146 ],\n",
              "       [-1.29285691,  0.26705087],\n",
              "       [-0.03928282, -1.1680935 ],\n",
              "       [ 0.52327666, -0.17154633],\n",
              "       [ 0.77179055,  0.82350415],\n",
              "       [ 2.16323595,  1.33652795],\n",
              "       [-0.36918184, -0.23937918],\n",
              "       [ 1.0996596 ,  0.65526373],\n",
              "       [ 0.64013153, -1.61695604],\n",
              "       [-0.02432612, -0.73803091],\n",
              "       [ 0.2799246 , -0.09815039],\n",
              "       [ 0.91017891,  0.31721822],\n",
              "       [ 0.78632796, -0.4664191 ],\n",
              "       [-0.94444626, -0.41004969],\n",
              "       [-0.01702041,  0.37915174],\n",
              "       [ 2.25930895, -0.04225715],\n",
              "       [-0.955945  , -0.34598178],\n",
              "       [-0.46359597,  0.48148147],\n",
              "       [-1.54079701,  0.06326199],\n",
              "       [ 0.15650654,  0.23218104],\n",
              "       [-0.59731607, -0.23792173],\n",
              "       [-1.42406091, -0.49331988],\n",
              "       [-0.54286148,  0.41605005],\n",
              "       [-1.15618243,  0.7811981 ],\n",
              "       [ 1.49448454, -2.06998503],\n",
              "       [ 0.42625873,  0.67690804],\n",
              "       [-0.63743703, -0.39727181],\n",
              "       [-0.13288058, -0.29779088],\n",
              "       [-0.30901297, -1.67600381],\n",
              "       [ 1.15233156,  1.07961859],\n",
              "       [-0.81336426, -1.46642433],\n",
              "       [ 0.52106488, -0.57578797],\n",
              "       [ 0.14195316, -0.31932842],\n",
              "       [ 0.69153875,  0.69474914],\n",
              "       [-0.72559738, -1.38336396],\n",
              "       [-1.5829384 ,  0.61037938],\n",
              "       [-1.18885926, -0.50681635],\n",
              "       [-0.59631404, -0.0525673 ],\n",
              "       [-1.93627981,  0.1887786 ],\n",
              "       [ 0.52389102,  0.08842209],\n",
              "       [-0.31088617,  0.09740017],\n",
              "       [ 0.39904635, -2.77259276],\n",
              "       [ 1.95591231,  0.39009332],\n",
              "       [-0.65240858, -0.39095338],\n",
              "       [ 0.49374178, -0.11610394],\n",
              "       [-2.03068447,  2.06449286],\n",
              "       [-0.11054066,  1.02017271],\n",
              "       [-0.69204985,  1.53637705],\n",
              "       [ 0.28634369,  0.60884383],\n",
              "       [-1.04525337,  1.21114529],\n",
              "       [ 0.68981816,  1.30184623],\n",
              "       [-0.62808756, -0.48102712],\n",
              "       [ 2.3039167 , -1.06001582],\n",
              "       [-0.1359497 ,  1.13689136],\n",
              "       [ 0.09772497,  0.58295368],\n",
              "       [-0.39944903,  0.37005589],\n",
              "       [-1.30652685,  1.65813068],\n",
              "       [-0.11816405, -0.6801782 ],\n",
              "       [ 0.66638308, -0.46071979],\n",
              "       [-1.33425847, -1.34671751],\n",
              "       [ 0.69377315, -0.15957344],\n",
              "       [-0.13370156,  1.07774381],\n",
              "       [-1.12682581, -0.73067775],\n",
              "       [-0.38487981,  0.09435159],\n",
              "       [-0.04217145, -0.28688719],\n",
              "       [-0.0616264 , -0.10730528],\n",
              "       [-0.71960439, -0.81299299],\n",
              "       [ 0.27451636, -0.89091508],\n",
              "       [-1.15735526, -0.31229225],\n",
              "       [-0.15766702,  2.2567235 ],\n",
              "       [-0.70470028,  0.94326072],\n",
              "       [ 0.74718833, -1.18894496],\n",
              "       [ 0.77325298, -1.18388064],\n",
              "       [-2.65917224,  0.60631952],\n",
              "       [-1.75589058,  0.45093446],\n",
              "       [-0.6840109 ,  1.6595508 ],\n",
              "       [ 1.0685094 , -0.4533858 ],\n",
              "       [-0.68783761, -1.2140774 ],\n",
              "       [-0.44092263, -0.2803555 ],\n",
              "       [-0.36469354,  0.15670386],\n",
              "       [ 0.5785215 ,  0.34965446],\n",
              "       [-0.76414392, -1.43779147],\n",
              "       [ 1.36453185, -0.68944918],\n",
              "       [-0.6522936 , -0.52118931],\n",
              "       [-1.84306955, -0.477974  ],\n",
              "       [-0.47965581,  0.6203583 ],\n",
              "       [ 0.69845715,  0.00377089],\n",
              "       [ 0.93184837,  0.33996498],\n",
              "       [-0.01568211,  0.16092817],\n",
              "       [-0.19065349, -0.39484951],\n",
              "       [-0.26773354, -1.12801133],\n",
              "       [ 0.28044171, -0.99312361],\n",
              "       [ 0.84163126, -0.24945858],\n",
              "       [ 0.04949498,  0.49383678],\n",
              "       [ 0.64331447, -1.57062341],\n",
              "       [-0.20690368,  0.88017891],\n",
              "       [-1.69810582,  0.38728048],\n",
              "       [-2.25556423, -1.02250684],\n",
              "       [ 0.03863055, -1.6567151 ],\n",
              "       [-0.98551074, -1.47183501],\n",
              "       [ 1.64813493,  0.16422776],\n",
              "       [ 0.56729028, -0.2226751 ],\n",
              "       [-0.35343175, -1.61647419],\n",
              "       [-0.29183736, -0.76149221],\n",
              "       [ 0.85792392,  1.14110187],\n",
              "       [ 1.46657872,  0.85255194],\n",
              "       [-0.59865394, -1.11589699],\n",
              "       [ 0.76666318,  0.35629282],\n",
              "       [-1.76853845,  0.35548179],\n",
              "       [ 0.81451982,  0.05892559],\n",
              "       [-0.18505367, -0.80764849],\n",
              "       [-1.4465347 ,  0.80029795],\n",
              "       [-0.30911444, -0.23346666],\n",
              "       [ 1.73272119,  0.68450111],\n",
              "       [ 0.370825  ,  0.14206181],\n",
              "       [ 1.51999486,  1.71958931],\n",
              "       [ 0.92950511,  0.58222459],\n",
              "       [-2.09460307,  0.12372191],\n",
              "       [-0.13010695,  0.09395323],\n",
              "       [ 0.94304609, -2.73967717],\n",
              "       [-0.56931205,  0.26990435],\n",
              "       [-0.46684555, -1.41690611],\n",
              "       [ 0.86896349,  0.27687191],\n",
              "       [-0.97110457,  0.3148172 ],\n",
              "       [ 0.82158571,  0.00529265],\n",
              "       [ 0.8005648 ,  0.07826018],\n",
              "       [-0.39522898, -1.15942052],\n",
              "       [-0.08593077,  0.19429294],\n",
              "       [ 0.87583276, -0.11510747],\n",
              "       [ 0.45741561, -0.96461201],\n",
              "       [-0.78262916, -0.1103893 ],\n",
              "       [-1.05462846,  0.82024784],\n",
              "       [ 0.46313033,  0.27909576],\n",
              "       [ 0.33890413,  2.02104356],\n",
              "       [-0.46886419, -2.20144129],\n",
              "       [ 0.1993002 , -0.05060354],\n",
              "       [-0.51751904, -0.97882986],\n",
              "       [-0.43918952,  0.18133843],\n",
              "       [-0.5028167 ,  2.41245368],\n",
              "       [-0.96050438, -0.79311736],\n",
              "       [-2.28862004,  0.25148442],\n",
              "       [-2.01640663, -0.53945463],\n",
              "       [-0.27567053, -0.70972797],\n",
              "       [ 1.73887268,  0.99439439],\n",
              "       [ 1.31913688, -0.88241882],\n",
              "       [ 1.12859406,  0.49600095],\n",
              "       [ 0.77140595,  1.02943883],\n",
              "       [-0.90876325, -0.42431762],\n",
              "       [ 0.86259601, -2.65561909],\n",
              "       [ 1.51332808,  0.55313206],\n",
              "       [-0.04570396,  0.22050766],\n",
              "       [-1.02993528, -0.34994336],\n",
              "       [ 1.10028434,  1.29802197],\n",
              "       [ 2.69622405, -0.07392467],\n",
              "       [-0.65855297, -0.51423397],\n",
              "       [-1.01804188, -0.07785476],\n",
              "       [ 0.38273243, -0.03424228],\n",
              "       [ 1.09634685, -0.2342158 ],\n",
              "       [-0.34745065, -0.58126848],\n",
              "       [-1.63263453, -1.56776772],\n",
              "       [-1.17915793,  1.30142807],\n",
              "       [ 0.89526027,  1.37496407],\n",
              "       [-1.33221165, -1.96862469],\n",
              "       [-0.66005632,  0.17581895],\n",
              "       [ 0.49869027,  1.04797216],\n",
              "       [ 0.28427967,  1.74266878],\n",
              "       [-0.22260568, -0.91307922],\n",
              "       [-1.68121822, -0.88897136],\n",
              "       [ 0.24211796, -0.88872026],\n",
              "       [ 0.93674246,  1.41232771],\n",
              "       [-2.36958691,  0.8640523 ],\n",
              "       [-2.23960406,  0.40149906],\n",
              "       [ 1.22487056,  0.06485611],\n",
              "       [-1.27968917, -0.5854312 ],\n",
              "       [-0.26164545, -0.18224478],\n",
              "       [-0.20289684, -0.10988278],\n",
              "       [ 0.21348005, -1.20857365],\n",
              "       [-0.24201983,  1.51826117],\n",
              "       [-0.38464542, -0.44383609],\n",
              "       [ 1.0781973 , -2.55918467],\n",
              "       [ 1.1813786 , -0.63190376],\n",
              "       [ 0.16392857,  0.09632136],\n",
              "       [ 0.94246812, -0.26759475],\n",
              "       [-0.67802578,  1.29784579],\n",
              "       [-2.36417382,  0.02033418],\n",
              "       [-1.34792542, -0.76157339],\n",
              "       [ 2.01125668, -0.04459543],\n",
              "       [ 0.1950697 , -1.78156286],\n",
              "       [-0.72904466,  0.1965574 ],\n",
              "       [ 0.35475769,  0.61688655],\n",
              "       [ 0.0086279 ,  0.52700421],\n",
              "       [ 0.45378191, -1.82974041],\n",
              "       [ 0.03700572,  0.76790241],\n",
              "       [ 0.58987982, -0.36385881],\n",
              "       [-0.80562651, -1.11831192],\n",
              "       [-0.13105401,  1.13307988],\n",
              "       [-1.9518041 , -0.65989173],\n",
              "       [-1.13980246,  0.78495752],\n",
              "       [-0.55430963, -0.47063766],\n",
              "       [-0.21694957,  0.44539325],\n",
              "       [-0.392389  , -3.04614305],\n",
              "       [ 0.54331189,  0.43904296],\n",
              "       [-0.21954103, -1.08403662],\n",
              "       [ 0.35178011,  0.37923553],\n",
              "       [-0.47003288, -0.21673147],\n",
              "       [-0.9301565 , -0.17858909]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-o2YVk082Qt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89ec0098-e82e-4b98-c1fb-3fde1f1b04c2"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrQ5i9x1859g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ab1d01a-5633-49a2-a6da-fad700456596"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfgKIdWB2A-e",
        "colab_type": "text"
      },
      "source": [
        "### Simple Perceptron\n",
        "Construct a simple perceptron using Keras. You model should have 1 dense layer with a single neuron and a sigmoid activation function. Your model should be called `model1` and make sure to save the results of your fit statement to a variable called `h1`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE4dINpB45pY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "463eb3ac-22df-4c0c-cee5-78fb993e27c1"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# This is our perceptron from Monday's by-hand: \n",
        "model1 = Sequential()\n",
        "model1.add(Dense(1, activation='sigmoid'))\n",
        "model1.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "h1 = model1.fit(X, y, epochs=500)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2484 - accuracy: 0.5433\n",
            "Epoch 2/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.5567\n",
            "Epoch 3/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.5667\n",
            "Epoch 4/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2478 - accuracy: 0.5700\n",
            "Epoch 5/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.5733\n",
            "Epoch 6/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2483 - accuracy: 0.5767\n",
            "Epoch 7/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.5833\n",
            "Epoch 8/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2466 - accuracy: 0.5900\n",
            "Epoch 9/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2488 - accuracy: 0.5933\n",
            "Epoch 10/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2475 - accuracy: 0.5967\n",
            "Epoch 11/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.6033\n",
            "Epoch 12/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.6100\n",
            "Epoch 13/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2479 - accuracy: 0.6100\n",
            "Epoch 14/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2488 - accuracy: 0.6100\n",
            "Epoch 15/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2465 - accuracy: 0.6067\n",
            "Epoch 16/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2472 - accuracy: 0.6067\n",
            "Epoch 17/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2461 - accuracy: 0.6133\n",
            "Epoch 18/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2481 - accuracy: 0.6133\n",
            "Epoch 19/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.6167\n",
            "Epoch 20/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.6133\n",
            "Epoch 21/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2484 - accuracy: 0.6200\n",
            "Epoch 22/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2471 - accuracy: 0.6200\n",
            "Epoch 23/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.6267\n",
            "Epoch 24/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.6233\n",
            "Epoch 25/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2458 - accuracy: 0.6267\n",
            "Epoch 26/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.6300\n",
            "Epoch 27/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2471 - accuracy: 0.6300\n",
            "Epoch 28/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2450 - accuracy: 0.6333\n",
            "Epoch 29/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.6333\n",
            "Epoch 30/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2447 - accuracy: 0.6300\n",
            "Epoch 31/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.6367\n",
            "Epoch 32/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.6433\n",
            "Epoch 33/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2474 - accuracy: 0.6467\n",
            "Epoch 34/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2450 - accuracy: 0.6467\n",
            "Epoch 35/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2475 - accuracy: 0.6467\n",
            "Epoch 36/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2462 - accuracy: 0.6433\n",
            "Epoch 37/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2466 - accuracy: 0.6500\n",
            "Epoch 38/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2448 - accuracy: 0.6467\n",
            "Epoch 39/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2481 - accuracy: 0.6567\n",
            "Epoch 40/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2445 - accuracy: 0.6600\n",
            "Epoch 41/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2465 - accuracy: 0.6600\n",
            "Epoch 42/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2434 - accuracy: 0.6633\n",
            "Epoch 43/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.6633\n",
            "Epoch 44/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2464 - accuracy: 0.6633\n",
            "Epoch 45/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2453 - accuracy: 0.6633\n",
            "Epoch 46/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.6633\n",
            "Epoch 47/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2471 - accuracy: 0.6633\n",
            "Epoch 48/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.6600\n",
            "Epoch 49/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.6633\n",
            "Epoch 50/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2465 - accuracy: 0.6700\n",
            "Epoch 51/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.6733\n",
            "Epoch 52/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2471 - accuracy: 0.6767\n",
            "Epoch 53/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.6733\n",
            "Epoch 54/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2448 - accuracy: 0.6733\n",
            "Epoch 55/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.6733\n",
            "Epoch 56/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2485 - accuracy: 0.6733\n",
            "Epoch 57/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.6767\n",
            "Epoch 58/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2438 - accuracy: 0.6733\n",
            "Epoch 59/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2466 - accuracy: 0.6767\n",
            "Epoch 60/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6767\n",
            "Epoch 61/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2457 - accuracy: 0.6767\n",
            "Epoch 62/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2471 - accuracy: 0.6733\n",
            "Epoch 63/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2456 - accuracy: 0.6733\n",
            "Epoch 64/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.6733\n",
            "Epoch 65/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.6733\n",
            "Epoch 66/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2492 - accuracy: 0.6733\n",
            "Epoch 67/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.6767\n",
            "Epoch 68/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2472 - accuracy: 0.6767\n",
            "Epoch 69/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2462 - accuracy: 0.6767\n",
            "Epoch 70/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.6767\n",
            "Epoch 71/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.6800\n",
            "Epoch 72/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.6800\n",
            "Epoch 73/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.6767\n",
            "Epoch 74/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.6800\n",
            "Epoch 75/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2473 - accuracy: 0.6800\n",
            "Epoch 76/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.6800\n",
            "Epoch 77/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2471 - accuracy: 0.6800\n",
            "Epoch 78/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2466 - accuracy: 0.6800\n",
            "Epoch 79/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2438 - accuracy: 0.6800\n",
            "Epoch 80/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2477 - accuracy: 0.6800\n",
            "Epoch 81/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2475 - accuracy: 0.6800\n",
            "Epoch 82/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.6800\n",
            "Epoch 83/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2456 - accuracy: 0.6800\n",
            "Epoch 84/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.6800\n",
            "Epoch 85/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2461 - accuracy: 0.6800\n",
            "Epoch 86/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.6800\n",
            "Epoch 87/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2477 - accuracy: 0.6800\n",
            "Epoch 88/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.6800\n",
            "Epoch 89/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.6800\n",
            "Epoch 90/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.6800\n",
            "Epoch 91/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2472 - accuracy: 0.6800\n",
            "Epoch 92/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2472 - accuracy: 0.6800\n",
            "Epoch 93/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.6800\n",
            "Epoch 94/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.6800\n",
            "Epoch 95/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.6800\n",
            "Epoch 96/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2458 - accuracy: 0.6800\n",
            "Epoch 97/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2457 - accuracy: 0.6800\n",
            "Epoch 98/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.6800\n",
            "Epoch 99/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2450 - accuracy: 0.6833\n",
            "Epoch 100/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.6833\n",
            "Epoch 101/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2472 - accuracy: 0.6800\n",
            "Epoch 102/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2458 - accuracy: 0.6800\n",
            "Epoch 103/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2457 - accuracy: 0.6833\n",
            "Epoch 104/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2484 - accuracy: 0.6867\n",
            "Epoch 105/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2473 - accuracy: 0.6867\n",
            "Epoch 106/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2443 - accuracy: 0.6900\n",
            "Epoch 107/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.6900\n",
            "Epoch 108/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2481 - accuracy: 0.6900\n",
            "Epoch 109/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.6900\n",
            "Epoch 110/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.6867\n",
            "Epoch 111/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.6867\n",
            "Epoch 112/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.6900\n",
            "Epoch 113/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2445 - accuracy: 0.6900\n",
            "Epoch 114/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.6900\n",
            "Epoch 115/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2457 - accuracy: 0.6900\n",
            "Epoch 116/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.6900\n",
            "Epoch 117/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2458 - accuracy: 0.6867\n",
            "Epoch 118/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2465 - accuracy: 0.6867\n",
            "Epoch 119/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2499 - accuracy: 0.6900\n",
            "Epoch 120/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.6900\n",
            "Epoch 121/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2474 - accuracy: 0.6900\n",
            "Epoch 122/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.6867\n",
            "Epoch 123/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.6867\n",
            "Epoch 124/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2446 - accuracy: 0.6867\n",
            "Epoch 125/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.6833\n",
            "Epoch 126/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2474 - accuracy: 0.6833\n",
            "Epoch 127/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2449 - accuracy: 0.6867\n",
            "Epoch 128/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2453 - accuracy: 0.6833\n",
            "Epoch 129/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2474 - accuracy: 0.6833\n",
            "Epoch 130/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.6833\n",
            "Epoch 131/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2473 - accuracy: 0.6833\n",
            "Epoch 132/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.6833\n",
            "Epoch 133/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.6800\n",
            "Epoch 134/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.6833\n",
            "Epoch 135/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2465 - accuracy: 0.6833\n",
            "Epoch 136/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2442 - accuracy: 0.6833\n",
            "Epoch 137/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2456 - accuracy: 0.6833\n",
            "Epoch 138/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2449 - accuracy: 0.6800\n",
            "Epoch 139/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.6833\n",
            "Epoch 140/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2442 - accuracy: 0.6800\n",
            "Epoch 141/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2445 - accuracy: 0.6833\n",
            "Epoch 142/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6867\n",
            "Epoch 143/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2494 - accuracy: 0.6800\n",
            "Epoch 144/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2498 - accuracy: 0.6800\n",
            "Epoch 145/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2472 - accuracy: 0.6833\n",
            "Epoch 146/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.6833\n",
            "Epoch 147/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2471 - accuracy: 0.6833\n",
            "Epoch 148/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2436 - accuracy: 0.6800\n",
            "Epoch 149/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.6800\n",
            "Epoch 150/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2461 - accuracy: 0.6833\n",
            "Epoch 151/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.6833\n",
            "Epoch 152/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2472 - accuracy: 0.6800\n",
            "Epoch 153/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2443 - accuracy: 0.6800\n",
            "Epoch 154/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.6833\n",
            "Epoch 155/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2457 - accuracy: 0.6800\n",
            "Epoch 156/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2479 - accuracy: 0.6800\n",
            "Epoch 157/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.6800\n",
            "Epoch 158/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2476 - accuracy: 0.6800\n",
            "Epoch 159/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.6800\n",
            "Epoch 160/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2478 - accuracy: 0.6800\n",
            "Epoch 161/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.6800\n",
            "Epoch 162/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2462 - accuracy: 0.6767\n",
            "Epoch 163/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2476 - accuracy: 0.6767\n",
            "Epoch 164/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.6800\n",
            "Epoch 165/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.6833\n",
            "Epoch 166/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2476 - accuracy: 0.6833\n",
            "Epoch 167/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2445 - accuracy: 0.6833\n",
            "Epoch 168/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2430 - accuracy: 0.6833\n",
            "Epoch 169/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2457 - accuracy: 0.6833\n",
            "Epoch 170/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.6833\n",
            "Epoch 171/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.6800\n",
            "Epoch 172/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2458 - accuracy: 0.6800\n",
            "Epoch 173/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.6800\n",
            "Epoch 174/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2478 - accuracy: 0.6800\n",
            "Epoch 175/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2461 - accuracy: 0.6800\n",
            "Epoch 176/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2496 - accuracy: 0.6800\n",
            "Epoch 177/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2480 - accuracy: 0.6800\n",
            "Epoch 178/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2488 - accuracy: 0.6800\n",
            "Epoch 179/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2487 - accuracy: 0.6800\n",
            "Epoch 180/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.6800\n",
            "Epoch 181/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2477 - accuracy: 0.6800\n",
            "Epoch 182/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2456 - accuracy: 0.6800\n",
            "Epoch 183/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.6800\n",
            "Epoch 184/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.6800\n",
            "Epoch 185/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.6800\n",
            "Epoch 186/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.6800\n",
            "Epoch 187/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2473 - accuracy: 0.6800\n",
            "Epoch 188/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2479 - accuracy: 0.6800\n",
            "Epoch 189/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2448 - accuracy: 0.6800\n",
            "Epoch 190/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.6800\n",
            "Epoch 191/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.6800\n",
            "Epoch 192/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6800\n",
            "Epoch 193/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2441 - accuracy: 0.6833\n",
            "Epoch 194/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2473 - accuracy: 0.6833\n",
            "Epoch 195/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2444 - accuracy: 0.6833\n",
            "Epoch 196/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2477 - accuracy: 0.6833\n",
            "Epoch 197/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2444 - accuracy: 0.6800\n",
            "Epoch 198/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.6800\n",
            "Epoch 199/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.6800\n",
            "Epoch 200/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2456 - accuracy: 0.6800\n",
            "Epoch 201/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.6800\n",
            "Epoch 202/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2466 - accuracy: 0.6800\n",
            "Epoch 203/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2471 - accuracy: 0.6800\n",
            "Epoch 204/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2466 - accuracy: 0.6800\n",
            "Epoch 205/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2449 - accuracy: 0.6800\n",
            "Epoch 206/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2444 - accuracy: 0.6800\n",
            "Epoch 207/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2479 - accuracy: 0.6800\n",
            "Epoch 208/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2464 - accuracy: 0.6800\n",
            "Epoch 209/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2442 - accuracy: 0.6800\n",
            "Epoch 210/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2465 - accuracy: 0.6800\n",
            "Epoch 211/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2464 - accuracy: 0.6800\n",
            "Epoch 212/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2453 - accuracy: 0.6800\n",
            "Epoch 213/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2471 - accuracy: 0.6800\n",
            "Epoch 214/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2448 - accuracy: 0.6800\n",
            "Epoch 215/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2473 - accuracy: 0.6800\n",
            "Epoch 216/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.6800\n",
            "Epoch 217/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2444 - accuracy: 0.6800\n",
            "Epoch 218/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.6800\n",
            "Epoch 219/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.6800\n",
            "Epoch 220/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.6800\n",
            "Epoch 221/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2481 - accuracy: 0.6800\n",
            "Epoch 222/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.6800\n",
            "Epoch 223/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2456 - accuracy: 0.6800\n",
            "Epoch 224/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2432 - accuracy: 0.6800\n",
            "Epoch 225/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2448 - accuracy: 0.6833\n",
            "Epoch 226/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2461 - accuracy: 0.6800\n",
            "Epoch 227/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2453 - accuracy: 0.6800\n",
            "Epoch 228/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2456 - accuracy: 0.6867\n",
            "Epoch 229/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2446 - accuracy: 0.6833\n",
            "Epoch 230/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2451 - accuracy: 0.6833\n",
            "Epoch 231/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2486 - accuracy: 0.6833\n",
            "Epoch 232/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2466 - accuracy: 0.6867\n",
            "Epoch 233/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2445 - accuracy: 0.6833\n",
            "Epoch 234/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.6833\n",
            "Epoch 235/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.6833\n",
            "Epoch 236/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2458 - accuracy: 0.6833\n",
            "Epoch 237/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.6833\n",
            "Epoch 238/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2456 - accuracy: 0.6833\n",
            "Epoch 239/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.6833\n",
            "Epoch 240/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2462 - accuracy: 0.6833\n",
            "Epoch 241/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.6833\n",
            "Epoch 242/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.6833\n",
            "Epoch 243/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2462 - accuracy: 0.6800\n",
            "Epoch 244/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.6833\n",
            "Epoch 245/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2497 - accuracy: 0.6833\n",
            "Epoch 246/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.6800\n",
            "Epoch 247/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.6800\n",
            "Epoch 248/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2486 - accuracy: 0.6800\n",
            "Epoch 249/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.6767\n",
            "Epoch 250/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2457 - accuracy: 0.6800\n",
            "Epoch 251/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.6800\n",
            "Epoch 252/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2457 - accuracy: 0.6767\n",
            "Epoch 253/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.6800\n",
            "Epoch 254/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2456 - accuracy: 0.6800\n",
            "Epoch 255/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.6800\n",
            "Epoch 256/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2443 - accuracy: 0.6800\n",
            "Epoch 257/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2443 - accuracy: 0.6833\n",
            "Epoch 258/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2443 - accuracy: 0.6833\n",
            "Epoch 259/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.6833\n",
            "Epoch 260/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2440 - accuracy: 0.6833\n",
            "Epoch 261/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2466 - accuracy: 0.6900\n",
            "Epoch 262/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2462 - accuracy: 0.6867\n",
            "Epoch 263/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2444 - accuracy: 0.6833\n",
            "Epoch 264/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2466 - accuracy: 0.6833\n",
            "Epoch 265/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2478 - accuracy: 0.6833\n",
            "Epoch 266/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.6833\n",
            "Epoch 267/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2446 - accuracy: 0.6800\n",
            "Epoch 268/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2475 - accuracy: 0.6800\n",
            "Epoch 269/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.6833\n",
            "Epoch 270/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2462 - accuracy: 0.6833\n",
            "Epoch 271/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2447 - accuracy: 0.6833\n",
            "Epoch 272/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2466 - accuracy: 0.6867\n",
            "Epoch 273/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2457 - accuracy: 0.6833\n",
            "Epoch 274/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2477 - accuracy: 0.6833\n",
            "Epoch 275/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2458 - accuracy: 0.6833\n",
            "Epoch 276/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2483 - accuracy: 0.6800\n",
            "Epoch 277/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2477 - accuracy: 0.6833\n",
            "Epoch 278/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.6833\n",
            "Epoch 279/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2451 - accuracy: 0.6833\n",
            "Epoch 280/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2453 - accuracy: 0.6867\n",
            "Epoch 281/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2451 - accuracy: 0.6867\n",
            "Epoch 282/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2462 - accuracy: 0.6867\n",
            "Epoch 283/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2483 - accuracy: 0.6867\n",
            "Epoch 284/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2458 - accuracy: 0.6867\n",
            "Epoch 285/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.6867\n",
            "Epoch 286/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2456 - accuracy: 0.6867\n",
            "Epoch 287/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.6867\n",
            "Epoch 288/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2483 - accuracy: 0.6867\n",
            "Epoch 289/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2481 - accuracy: 0.6867\n",
            "Epoch 290/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2461 - accuracy: 0.6867\n",
            "Epoch 291/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2446 - accuracy: 0.6833\n",
            "Epoch 292/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.6800\n",
            "Epoch 293/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2447 - accuracy: 0.6800\n",
            "Epoch 294/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2472 - accuracy: 0.6867\n",
            "Epoch 295/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.6833\n",
            "Epoch 296/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.6833\n",
            "Epoch 297/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2472 - accuracy: 0.6833\n",
            "Epoch 298/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2464 - accuracy: 0.6867\n",
            "Epoch 299/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2449 - accuracy: 0.6833\n",
            "Epoch 300/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2445 - accuracy: 0.6867\n",
            "Epoch 301/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2453 - accuracy: 0.6867\n",
            "Epoch 302/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.6867\n",
            "Epoch 303/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.6867\n",
            "Epoch 304/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2464 - accuracy: 0.6867\n",
            "Epoch 305/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.6867\n",
            "Epoch 306/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2484 - accuracy: 0.6867\n",
            "Epoch 307/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.6867\n",
            "Epoch 308/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2465 - accuracy: 0.6867\n",
            "Epoch 309/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2483 - accuracy: 0.6867\n",
            "Epoch 310/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2457 - accuracy: 0.6900\n",
            "Epoch 311/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.6933\n",
            "Epoch 312/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.6933\n",
            "Epoch 313/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.6900\n",
            "Epoch 314/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2457 - accuracy: 0.6900\n",
            "Epoch 315/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.6867\n",
            "Epoch 316/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2449 - accuracy: 0.6867\n",
            "Epoch 317/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.6867\n",
            "Epoch 318/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.6900\n",
            "Epoch 319/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2471 - accuracy: 0.6867\n",
            "Epoch 320/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2458 - accuracy: 0.6867\n",
            "Epoch 321/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2446 - accuracy: 0.6867\n",
            "Epoch 322/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.6867\n",
            "Epoch 323/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.6900\n",
            "Epoch 324/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.6933\n",
            "Epoch 325/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2446 - accuracy: 0.6933\n",
            "Epoch 326/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.6933\n",
            "Epoch 327/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.6933\n",
            "Epoch 328/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2481 - accuracy: 0.6933\n",
            "Epoch 329/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.6900\n",
            "Epoch 330/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2464 - accuracy: 0.6900\n",
            "Epoch 331/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2466 - accuracy: 0.6900\n",
            "Epoch 332/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2472 - accuracy: 0.6867\n",
            "Epoch 333/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.6867\n",
            "Epoch 334/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2481 - accuracy: 0.6867\n",
            "Epoch 335/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.6867\n",
            "Epoch 336/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2450 - accuracy: 0.6867\n",
            "Epoch 337/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2458 - accuracy: 0.6900\n",
            "Epoch 338/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2461 - accuracy: 0.6900\n",
            "Epoch 339/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.6900\n",
            "Epoch 340/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2457 - accuracy: 0.6900\n",
            "Epoch 341/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2464 - accuracy: 0.6900\n",
            "Epoch 342/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.6933\n",
            "Epoch 343/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.6933\n",
            "Epoch 344/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.6933\n",
            "Epoch 345/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.6900\n",
            "Epoch 346/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.6933\n",
            "Epoch 347/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2457 - accuracy: 0.6933\n",
            "Epoch 348/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.6933\n",
            "Epoch 349/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.6933\n",
            "Epoch 350/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2479 - accuracy: 0.6933\n",
            "Epoch 351/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.6900\n",
            "Epoch 352/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.6900\n",
            "Epoch 353/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.6900\n",
            "Epoch 354/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2466 - accuracy: 0.6867\n",
            "Epoch 355/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.6833\n",
            "Epoch 356/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2461 - accuracy: 0.6833\n",
            "Epoch 357/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2451 - accuracy: 0.6833\n",
            "Epoch 358/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.6833\n",
            "Epoch 359/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2466 - accuracy: 0.6867\n",
            "Epoch 360/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.6867\n",
            "Epoch 361/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.6867\n",
            "Epoch 362/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.6833\n",
            "Epoch 363/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2462 - accuracy: 0.6867\n",
            "Epoch 364/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2451 - accuracy: 0.6800\n",
            "Epoch 365/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2483 - accuracy: 0.6833\n",
            "Epoch 366/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2448 - accuracy: 0.6833\n",
            "Epoch 367/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.6833\n",
            "Epoch 368/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2443 - accuracy: 0.6867\n",
            "Epoch 369/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2456 - accuracy: 0.6867\n",
            "Epoch 370/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.6867\n",
            "Epoch 371/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2473 - accuracy: 0.6867\n",
            "Epoch 372/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.6867\n",
            "Epoch 373/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.6833\n",
            "Epoch 374/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.6833\n",
            "Epoch 375/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.6867\n",
            "Epoch 376/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.6867\n",
            "Epoch 377/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2477 - accuracy: 0.6867\n",
            "Epoch 378/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.6867\n",
            "Epoch 379/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.6867\n",
            "Epoch 380/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.6867\n",
            "Epoch 381/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.6867\n",
            "Epoch 382/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2456 - accuracy: 0.6867\n",
            "Epoch 383/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2476 - accuracy: 0.6867\n",
            "Epoch 384/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2500 - accuracy: 0.6867\n",
            "Epoch 385/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2442 - accuracy: 0.6867\n",
            "Epoch 386/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2488 - accuracy: 0.6867\n",
            "Epoch 387/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.6833\n",
            "Epoch 388/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2442 - accuracy: 0.6833\n",
            "Epoch 389/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.6833\n",
            "Epoch 390/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2475 - accuracy: 0.6800\n",
            "Epoch 391/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2472 - accuracy: 0.6800\n",
            "Epoch 392/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2461 - accuracy: 0.6800\n",
            "Epoch 393/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2476 - accuracy: 0.6800\n",
            "Epoch 394/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.6833\n",
            "Epoch 395/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2461 - accuracy: 0.6833\n",
            "Epoch 396/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.6833\n",
            "Epoch 397/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.6800\n",
            "Epoch 398/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2448 - accuracy: 0.6800\n",
            "Epoch 399/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2474 - accuracy: 0.6800\n",
            "Epoch 400/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2446 - accuracy: 0.6800\n",
            "Epoch 401/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.6800\n",
            "Epoch 402/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2464 - accuracy: 0.6800\n",
            "Epoch 403/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.6800\n",
            "Epoch 404/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.6800\n",
            "Epoch 405/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.6800\n",
            "Epoch 406/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2439 - accuracy: 0.6833\n",
            "Epoch 407/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.6833\n",
            "Epoch 408/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.6833\n",
            "Epoch 409/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2484 - accuracy: 0.6800\n",
            "Epoch 410/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2449 - accuracy: 0.6800\n",
            "Epoch 411/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.6800\n",
            "Epoch 412/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2466 - accuracy: 0.6800\n",
            "Epoch 413/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.6800\n",
            "Epoch 414/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.6833\n",
            "Epoch 415/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2441 - accuracy: 0.6800\n",
            "Epoch 416/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2466 - accuracy: 0.6800\n",
            "Epoch 417/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2478 - accuracy: 0.6833\n",
            "Epoch 418/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.6800\n",
            "Epoch 419/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2449 - accuracy: 0.6800\n",
            "Epoch 420/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2438 - accuracy: 0.6800\n",
            "Epoch 421/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2458 - accuracy: 0.6800\n",
            "Epoch 422/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.6833\n",
            "Epoch 423/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2473 - accuracy: 0.6833\n",
            "Epoch 424/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.6833\n",
            "Epoch 425/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2466 - accuracy: 0.6800\n",
            "Epoch 426/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.6767\n",
            "Epoch 427/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.6767\n",
            "Epoch 428/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2482 - accuracy: 0.6800\n",
            "Epoch 429/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2477 - accuracy: 0.6767\n",
            "Epoch 430/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2435 - accuracy: 0.6833\n",
            "Epoch 431/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.6833\n",
            "Epoch 432/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2473 - accuracy: 0.6800\n",
            "Epoch 433/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2481 - accuracy: 0.6800\n",
            "Epoch 434/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.6800\n",
            "Epoch 435/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.6833\n",
            "Epoch 436/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.6800\n",
            "Epoch 437/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2437 - accuracy: 0.6833\n",
            "Epoch 438/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2456 - accuracy: 0.6800\n",
            "Epoch 439/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2475 - accuracy: 0.6800\n",
            "Epoch 440/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.6800\n",
            "Epoch 441/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2464 - accuracy: 0.6800\n",
            "Epoch 442/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.6767\n",
            "Epoch 443/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2461 - accuracy: 0.6767\n",
            "Epoch 444/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.6800\n",
            "Epoch 445/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.6800\n",
            "Epoch 446/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2462 - accuracy: 0.6767\n",
            "Epoch 447/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2472 - accuracy: 0.6833\n",
            "Epoch 448/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2472 - accuracy: 0.6767\n",
            "Epoch 449/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2458 - accuracy: 0.6800\n",
            "Epoch 450/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.6833\n",
            "Epoch 451/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.6867\n",
            "Epoch 452/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.6867\n",
            "Epoch 453/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.6867\n",
            "Epoch 454/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2453 - accuracy: 0.6833\n",
            "Epoch 455/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2476 - accuracy: 0.6833\n",
            "Epoch 456/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2442 - accuracy: 0.6867\n",
            "Epoch 457/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2446 - accuracy: 0.6867\n",
            "Epoch 458/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.6867\n",
            "Epoch 459/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2484 - accuracy: 0.6833\n",
            "Epoch 460/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2477 - accuracy: 0.6833\n",
            "Epoch 461/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2465 - accuracy: 0.6833\n",
            "Epoch 462/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2450 - accuracy: 0.6833\n",
            "Epoch 463/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2457 - accuracy: 0.6833\n",
            "Epoch 464/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.6833\n",
            "Epoch 465/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.6833\n",
            "Epoch 466/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.6833\n",
            "Epoch 467/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2472 - accuracy: 0.6833\n",
            "Epoch 468/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.6833\n",
            "Epoch 469/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2465 - accuracy: 0.6833\n",
            "Epoch 470/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2458 - accuracy: 0.6833\n",
            "Epoch 471/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2451 - accuracy: 0.6833\n",
            "Epoch 472/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.6833\n",
            "Epoch 473/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2471 - accuracy: 0.6767\n",
            "Epoch 474/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2464 - accuracy: 0.6767\n",
            "Epoch 475/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2486 - accuracy: 0.6800\n",
            "Epoch 476/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2430 - accuracy: 0.6800\n",
            "Epoch 477/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2462 - accuracy: 0.6833\n",
            "Epoch 478/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2458 - accuracy: 0.6833\n",
            "Epoch 479/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2488 - accuracy: 0.6833\n",
            "Epoch 480/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.6833\n",
            "Epoch 481/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2451 - accuracy: 0.6833\n",
            "Epoch 482/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.6800\n",
            "Epoch 483/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2441 - accuracy: 0.6867\n",
            "Epoch 484/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2449 - accuracy: 0.6867\n",
            "Epoch 485/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2453 - accuracy: 0.6867\n",
            "Epoch 486/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.6867\n",
            "Epoch 487/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2477 - accuracy: 0.6867\n",
            "Epoch 488/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2442 - accuracy: 0.6867\n",
            "Epoch 489/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2464 - accuracy: 0.6867\n",
            "Epoch 490/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2449 - accuracy: 0.6867\n",
            "Epoch 491/500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.6867\n",
            "Epoch 492/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2471 - accuracy: 0.6867\n",
            "Epoch 493/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.6867\n",
            "Epoch 494/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2449 - accuracy: 0.6867\n",
            "Epoch 495/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2465 - accuracy: 0.6867\n",
            "Epoch 496/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2485 - accuracy: 0.6833\n",
            "Epoch 497/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2444 - accuracy: 0.6867\n",
            "Epoch 498/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2447 - accuracy: 0.6867\n",
            "Epoch 499/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2475 - accuracy: 0.6833\n",
            "Epoch 500/500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2471 - accuracy: 0.6833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXpDsJBn2A-j",
        "colab_type": "text"
      },
      "source": [
        "### Multi-Layer Perceptron\n",
        "Now construct a multi-layer perceptron using Keras. Here are some architecture suggestions: \n",
        "- 2 Hidden Layers\n",
        "- 5-32 Neurons in the Hidden Layers\n",
        "- Your pick of activation function and optimizer\n",
        "- Incorporate the Callback function below into your model\n",
        "\n",
        "Your model should be called `model2` and make sure to save the results of your fit statement to a variable called `h2`. You must also monitor the metric 'accuracy'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TQeYD3x2A-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback): \n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "        if(logs.get('accuracy') > .99999):   \n",
        "            self.model.stop_training = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASZuQCsG2A-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for comparison only:\n",
        "# This is our perceptron from Monday's by-hand: \n",
        "model1 = Sequential()\n",
        "model1.add(Dense(1, activation='sigmoid'))\n",
        "model1.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "h1 = model1.fit(X, y, epochs=500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nszzc2826Qyn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b5742674-001a-4abc-d73e-8c47b60975ca"
      },
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Dense(2, input_dim=2, activation='sigmoid'))\n",
        "model2.add(Dense(10, activation='relu'))\n",
        "model2.add(Dense(32, activation='relu'))\n",
        "model2.add(Dense(1, activation='sigmoid'))\n",
        "model2.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "h2 = model2.fit(X, y, epochs=1500, callbacks=[myCallback()])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.5333\n",
            "Epoch 2/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.5267\n",
            "Epoch 3/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2479 - accuracy: 0.5267\n",
            "Epoch 4/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2483 - accuracy: 0.5267\n",
            "Epoch 5/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.5267\n",
            "Epoch 6/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2473 - accuracy: 0.5267\n",
            "Epoch 7/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.5267\n",
            "Epoch 8/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2462 - accuracy: 0.5267\n",
            "Epoch 9/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.5267\n",
            "Epoch 10/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.5267\n",
            "Epoch 11/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2453 - accuracy: 0.5267\n",
            "Epoch 12/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2443 - accuracy: 0.5267\n",
            "Epoch 13/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2440 - accuracy: 0.5267\n",
            "Epoch 14/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2433 - accuracy: 0.5267\n",
            "Epoch 15/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2436 - accuracy: 0.5267\n",
            "Epoch 16/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2418 - accuracy: 0.5267\n",
            "Epoch 17/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2422 - accuracy: 0.5267\n",
            "Epoch 18/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2419 - accuracy: 0.5500\n",
            "Epoch 19/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2408 - accuracy: 0.5967\n",
            "Epoch 20/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.6133\n",
            "Epoch 21/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2407 - accuracy: 0.6233\n",
            "Epoch 22/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2392 - accuracy: 0.6533\n",
            "Epoch 23/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2391 - accuracy: 0.7267\n",
            "Epoch 24/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2379 - accuracy: 0.6700\n",
            "Epoch 25/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2377 - accuracy: 0.5700\n",
            "Epoch 26/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2376 - accuracy: 0.5700\n",
            "Epoch 27/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2359 - accuracy: 0.6000\n",
            "Epoch 28/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2342 - accuracy: 0.5767\n",
            "Epoch 29/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2331 - accuracy: 0.5533\n",
            "Epoch 30/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2320 - accuracy: 0.5500\n",
            "Epoch 31/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2324 - accuracy: 0.5500\n",
            "Epoch 32/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2321 - accuracy: 0.5900\n",
            "Epoch 33/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2302 - accuracy: 0.5800\n",
            "Epoch 34/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2320 - accuracy: 0.5600\n",
            "Epoch 35/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2290 - accuracy: 0.5733\n",
            "Epoch 36/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2275 - accuracy: 0.5833\n",
            "Epoch 37/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2282 - accuracy: 0.5833\n",
            "Epoch 38/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2295 - accuracy: 0.5867\n",
            "Epoch 39/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2254 - accuracy: 0.6167\n",
            "Epoch 40/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 0.6067\n",
            "Epoch 41/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2238 - accuracy: 0.6200\n",
            "Epoch 42/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2201 - accuracy: 0.6200\n",
            "Epoch 43/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.6333\n",
            "Epoch 44/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2212 - accuracy: 0.6600\n",
            "Epoch 45/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2209 - accuracy: 0.6700\n",
            "Epoch 46/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2201 - accuracy: 0.6133\n",
            "Epoch 47/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2166 - accuracy: 0.6133\n",
            "Epoch 48/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2148 - accuracy: 0.6567\n",
            "Epoch 49/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2162 - accuracy: 0.6667\n",
            "Epoch 50/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2137 - accuracy: 0.6767\n",
            "Epoch 51/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2134 - accuracy: 0.6733\n",
            "Epoch 52/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2127 - accuracy: 0.6767\n",
            "Epoch 53/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2138 - accuracy: 0.6933\n",
            "Epoch 54/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2105 - accuracy: 0.7067\n",
            "Epoch 55/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2088 - accuracy: 0.7333\n",
            "Epoch 56/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2040 - accuracy: 0.7400\n",
            "Epoch 57/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2052 - accuracy: 0.7233\n",
            "Epoch 58/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2061 - accuracy: 0.7433\n",
            "Epoch 59/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2032 - accuracy: 0.7400\n",
            "Epoch 60/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1998 - accuracy: 0.7533\n",
            "Epoch 61/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1939 - accuracy: 0.7567\n",
            "Epoch 62/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1987 - accuracy: 0.7467\n",
            "Epoch 63/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1940 - accuracy: 0.7633\n",
            "Epoch 64/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1953 - accuracy: 0.7833\n",
            "Epoch 65/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1896 - accuracy: 0.7867\n",
            "Epoch 66/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.7833\n",
            "Epoch 67/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1851 - accuracy: 0.7867\n",
            "Epoch 68/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7967\n",
            "Epoch 69/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1798 - accuracy: 0.8033\n",
            "Epoch 70/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.8133\n",
            "Epoch 71/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1773 - accuracy: 0.7967\n",
            "Epoch 72/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1790 - accuracy: 0.7900\n",
            "Epoch 73/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1765 - accuracy: 0.8100\n",
            "Epoch 74/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1702 - accuracy: 0.8033\n",
            "Epoch 75/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1663 - accuracy: 0.8133\n",
            "Epoch 76/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1625 - accuracy: 0.8133\n",
            "Epoch 77/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1660 - accuracy: 0.8100\n",
            "Epoch 78/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1625 - accuracy: 0.8067\n",
            "Epoch 79/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1586 - accuracy: 0.8167\n",
            "Epoch 80/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1551 - accuracy: 0.8200\n",
            "Epoch 81/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1543 - accuracy: 0.8200\n",
            "Epoch 82/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1545 - accuracy: 0.8333\n",
            "Epoch 83/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1582 - accuracy: 0.8233\n",
            "Epoch 84/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1462 - accuracy: 0.8167\n",
            "Epoch 85/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1454 - accuracy: 0.8267\n",
            "Epoch 86/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1450 - accuracy: 0.8267\n",
            "Epoch 87/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1435 - accuracy: 0.8367\n",
            "Epoch 88/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1397 - accuracy: 0.8233\n",
            "Epoch 89/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1399 - accuracy: 0.8300\n",
            "Epoch 90/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1358 - accuracy: 0.8367\n",
            "Epoch 91/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1360 - accuracy: 0.8400\n",
            "Epoch 92/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1361 - accuracy: 0.8333\n",
            "Epoch 93/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1287 - accuracy: 0.8433\n",
            "Epoch 94/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1328 - accuracy: 0.8500\n",
            "Epoch 95/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1269 - accuracy: 0.8533\n",
            "Epoch 96/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1249 - accuracy: 0.8567\n",
            "Epoch 97/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1295 - accuracy: 0.8533\n",
            "Epoch 98/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1256 - accuracy: 0.8700\n",
            "Epoch 99/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1210 - accuracy: 0.8667\n",
            "Epoch 100/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1176 - accuracy: 0.8600\n",
            "Epoch 101/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1175 - accuracy: 0.8667\n",
            "Epoch 102/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1127 - accuracy: 0.8667\n",
            "Epoch 103/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1148 - accuracy: 0.8767\n",
            "Epoch 104/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1133 - accuracy: 0.8767\n",
            "Epoch 105/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1146 - accuracy: 0.8767\n",
            "Epoch 106/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1076 - accuracy: 0.8800\n",
            "Epoch 107/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1115 - accuracy: 0.8767\n",
            "Epoch 108/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.8800\n",
            "Epoch 109/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1038 - accuracy: 0.8833\n",
            "Epoch 110/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1042 - accuracy: 0.8800\n",
            "Epoch 111/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1039 - accuracy: 0.8833\n",
            "Epoch 112/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1003 - accuracy: 0.8967\n",
            "Epoch 113/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1017 - accuracy: 0.8967\n",
            "Epoch 114/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1011 - accuracy: 0.8967\n",
            "Epoch 115/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0991 - accuracy: 0.9067\n",
            "Epoch 116/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0918 - accuracy: 0.9000\n",
            "Epoch 117/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0919 - accuracy: 0.9000\n",
            "Epoch 118/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0911 - accuracy: 0.9067\n",
            "Epoch 119/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0917 - accuracy: 0.9067\n",
            "Epoch 120/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0870 - accuracy: 0.9100\n",
            "Epoch 121/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0872 - accuracy: 0.9033\n",
            "Epoch 122/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0850 - accuracy: 0.9067\n",
            "Epoch 123/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0854 - accuracy: 0.9133\n",
            "Epoch 124/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0838 - accuracy: 0.9133\n",
            "Epoch 125/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0810 - accuracy: 0.9100\n",
            "Epoch 126/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0814 - accuracy: 0.9167\n",
            "Epoch 127/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0844 - accuracy: 0.9200\n",
            "Epoch 128/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0780 - accuracy: 0.9267\n",
            "Epoch 129/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0790 - accuracy: 0.9200\n",
            "Epoch 130/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0767 - accuracy: 0.9233\n",
            "Epoch 131/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0739 - accuracy: 0.9267\n",
            "Epoch 132/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0738 - accuracy: 0.9267\n",
            "Epoch 133/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0708 - accuracy: 0.9333\n",
            "Epoch 134/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0760 - accuracy: 0.9267\n",
            "Epoch 135/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0746 - accuracy: 0.9267\n",
            "Epoch 136/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.9333\n",
            "Epoch 137/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0704 - accuracy: 0.9333\n",
            "Epoch 138/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0694 - accuracy: 0.9333\n",
            "Epoch 139/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.9333\n",
            "Epoch 140/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.9333\n",
            "Epoch 141/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0670 - accuracy: 0.9433\n",
            "Epoch 142/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.9367\n",
            "Epoch 143/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0628 - accuracy: 0.9400\n",
            "Epoch 144/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0622 - accuracy: 0.9467\n",
            "Epoch 145/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.9467\n",
            "Epoch 146/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0616 - accuracy: 0.9400\n",
            "Epoch 147/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0615 - accuracy: 0.9400\n",
            "Epoch 148/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0587 - accuracy: 0.9467\n",
            "Epoch 149/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0564 - accuracy: 0.9433\n",
            "Epoch 150/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0570 - accuracy: 0.9500\n",
            "Epoch 151/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0556 - accuracy: 0.9500\n",
            "Epoch 152/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0564 - accuracy: 0.9500\n",
            "Epoch 153/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0548 - accuracy: 0.9467\n",
            "Epoch 154/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0543 - accuracy: 0.9500\n",
            "Epoch 155/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.9500\n",
            "Epoch 156/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0530 - accuracy: 0.9600\n",
            "Epoch 157/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0515 - accuracy: 0.9600\n",
            "Epoch 158/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0541 - accuracy: 0.9567\n",
            "Epoch 159/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0509 - accuracy: 0.9600\n",
            "Epoch 160/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0525 - accuracy: 0.9600\n",
            "Epoch 161/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0501 - accuracy: 0.9600\n",
            "Epoch 162/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0480 - accuracy: 0.9633\n",
            "Epoch 163/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 0.9633\n",
            "Epoch 164/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0464 - accuracy: 0.9667\n",
            "Epoch 165/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 0.9667\n",
            "Epoch 166/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0462 - accuracy: 0.9667\n",
            "Epoch 167/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0472 - accuracy: 0.9633\n",
            "Epoch 168/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0452 - accuracy: 0.9700\n",
            "Epoch 169/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0424 - accuracy: 0.9667\n",
            "Epoch 170/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0444 - accuracy: 0.9667\n",
            "Epoch 171/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0414 - accuracy: 0.9700\n",
            "Epoch 172/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0417 - accuracy: 0.9700\n",
            "Epoch 173/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0413 - accuracy: 0.9700\n",
            "Epoch 174/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 0.9700\n",
            "Epoch 175/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0395 - accuracy: 0.9700\n",
            "Epoch 176/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0449 - accuracy: 0.9700\n",
            "Epoch 177/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0409 - accuracy: 0.9700\n",
            "Epoch 178/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.9700\n",
            "Epoch 179/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0390 - accuracy: 0.9733\n",
            "Epoch 180/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0420 - accuracy: 0.9700\n",
            "Epoch 181/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0381 - accuracy: 0.9700\n",
            "Epoch 182/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0374 - accuracy: 0.9767\n",
            "Epoch 183/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0356 - accuracy: 0.9733\n",
            "Epoch 184/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0355 - accuracy: 0.9733\n",
            "Epoch 185/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0376 - accuracy: 0.9767\n",
            "Epoch 186/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0355 - accuracy: 0.9767\n",
            "Epoch 187/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0361 - accuracy: 0.9733\n",
            "Epoch 188/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9767\n",
            "Epoch 189/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9700\n",
            "Epoch 190/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9767\n",
            "Epoch 191/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0331 - accuracy: 0.9800\n",
            "Epoch 192/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0345 - accuracy: 0.9800\n",
            "Epoch 193/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0323 - accuracy: 0.9800\n",
            "Epoch 194/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0329 - accuracy: 0.9800\n",
            "Epoch 195/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0322 - accuracy: 0.9833\n",
            "Epoch 196/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0308 - accuracy: 0.9833\n",
            "Epoch 197/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0320 - accuracy: 0.9800\n",
            "Epoch 198/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0322 - accuracy: 0.9800\n",
            "Epoch 199/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0296 - accuracy: 0.9800\n",
            "Epoch 200/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 0.9833\n",
            "Epoch 201/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0322 - accuracy: 0.9833\n",
            "Epoch 202/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0297 - accuracy: 0.9800\n",
            "Epoch 203/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0288 - accuracy: 0.9833\n",
            "Epoch 204/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0277 - accuracy: 0.9833\n",
            "Epoch 205/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0276 - accuracy: 0.9833\n",
            "Epoch 206/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0281 - accuracy: 0.9833\n",
            "Epoch 207/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.9867\n",
            "Epoch 208/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0264 - accuracy: 0.9867\n",
            "Epoch 209/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0269 - accuracy: 0.9833\n",
            "Epoch 210/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.9833\n",
            "Epoch 211/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0260 - accuracy: 0.9833\n",
            "Epoch 212/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0264 - accuracy: 0.9867\n",
            "Epoch 213/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0281 - accuracy: 0.9867\n",
            "Epoch 214/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 0.9833\n",
            "Epoch 215/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 0.9867\n",
            "Epoch 216/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 0.9867\n",
            "Epoch 217/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0250 - accuracy: 0.9867\n",
            "Epoch 218/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0261 - accuracy: 0.9867\n",
            "Epoch 219/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0242 - accuracy: 0.9867\n",
            "Epoch 220/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.9867\n",
            "Epoch 221/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 0.9867\n",
            "Epoch 222/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0268 - accuracy: 0.9867\n",
            "Epoch 223/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0233 - accuracy: 0.9867\n",
            "Epoch 224/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.9867\n",
            "Epoch 225/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0226 - accuracy: 0.9900\n",
            "Epoch 226/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0227 - accuracy: 0.9833\n",
            "Epoch 227/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0227 - accuracy: 0.9867\n",
            "Epoch 228/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 0.9867\n",
            "Epoch 229/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 0.9867\n",
            "Epoch 230/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0241 - accuracy: 0.9867\n",
            "Epoch 231/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0231 - accuracy: 0.9867\n",
            "Epoch 232/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 0.9867\n",
            "Epoch 233/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0221 - accuracy: 0.9867\n",
            "Epoch 234/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 0.9867\n",
            "Epoch 235/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 0.9900\n",
            "Epoch 236/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0244 - accuracy: 0.9867\n",
            "Epoch 237/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 0.9867\n",
            "Epoch 238/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0207 - accuracy: 0.9867\n",
            "Epoch 239/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0234 - accuracy: 0.9867\n",
            "Epoch 240/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0222 - accuracy: 0.9867\n",
            "Epoch 241/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 0.9867\n",
            "Epoch 242/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0198 - accuracy: 0.9867\n",
            "Epoch 243/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 0.9867\n",
            "Epoch 244/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0202 - accuracy: 0.9867\n",
            "Epoch 245/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0201 - accuracy: 0.9867\n",
            "Epoch 246/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 0.9867\n",
            "Epoch 247/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0202 - accuracy: 0.9867\n",
            "Epoch 248/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0232 - accuracy: 0.9867\n",
            "Epoch 249/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0196 - accuracy: 0.9867\n",
            "Epoch 250/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 0.9867\n",
            "Epoch 251/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0186 - accuracy: 0.9833\n",
            "Epoch 252/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0205 - accuracy: 0.9867\n",
            "Epoch 253/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0226 - accuracy: 0.9867\n",
            "Epoch 254/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0193 - accuracy: 0.9900\n",
            "Epoch 255/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 0.9867\n",
            "Epoch 256/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 0.9867\n",
            "Epoch 257/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0184 - accuracy: 0.9867\n",
            "Epoch 258/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0178 - accuracy: 0.9867\n",
            "Epoch 259/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0177 - accuracy: 0.9867\n",
            "Epoch 260/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0189 - accuracy: 0.9867\n",
            "Epoch 261/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 0.9900\n",
            "Epoch 262/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0184 - accuracy: 0.9867\n",
            "Epoch 263/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0180 - accuracy: 0.9867\n",
            "Epoch 264/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0184 - accuracy: 0.9867\n",
            "Epoch 265/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0174 - accuracy: 0.9900\n",
            "Epoch 266/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 0.9867\n",
            "Epoch 267/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 0.9867\n",
            "Epoch 268/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0173 - accuracy: 0.9900\n",
            "Epoch 269/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0173 - accuracy: 0.9867\n",
            "Epoch 270/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0167 - accuracy: 0.9867\n",
            "Epoch 271/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0179 - accuracy: 0.9867\n",
            "Epoch 272/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 0.9900\n",
            "Epoch 273/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0170 - accuracy: 0.9900\n",
            "Epoch 274/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0160 - accuracy: 0.9900\n",
            "Epoch 275/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0196 - accuracy: 0.9900\n",
            "Epoch 276/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0158 - accuracy: 0.9867\n",
            "Epoch 277/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9900\n",
            "Epoch 278/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0154 - accuracy: 0.9900\n",
            "Epoch 279/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0179 - accuracy: 0.9900\n",
            "Epoch 280/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0175 - accuracy: 0.9867\n",
            "Epoch 281/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 0.9867\n",
            "Epoch 282/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0162 - accuracy: 0.9900\n",
            "Epoch 283/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0171 - accuracy: 0.9900\n",
            "Epoch 284/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 0.9900\n",
            "Epoch 285/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0183 - accuracy: 0.9900\n",
            "Epoch 286/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 0.9900\n",
            "Epoch 287/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0169 - accuracy: 0.9900\n",
            "Epoch 288/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0151 - accuracy: 0.9900\n",
            "Epoch 289/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0153 - accuracy: 0.9900\n",
            "Epoch 290/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0147 - accuracy: 0.9900\n",
            "Epoch 291/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0146 - accuracy: 0.9900\n",
            "Epoch 292/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0159 - accuracy: 0.9933\n",
            "Epoch 293/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0147 - accuracy: 0.9900\n",
            "Epoch 294/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0163 - accuracy: 0.9900\n",
            "Epoch 295/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0162 - accuracy: 0.9900\n",
            "Epoch 296/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0146 - accuracy: 0.9900\n",
            "Epoch 297/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0168 - accuracy: 0.9867\n",
            "Epoch 298/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0148 - accuracy: 0.9867\n",
            "Epoch 299/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.9867\n",
            "Epoch 300/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 0.9900\n",
            "Epoch 301/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0144 - accuracy: 0.9900\n",
            "Epoch 302/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0140 - accuracy: 0.9900\n",
            "Epoch 303/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0140 - accuracy: 0.9933\n",
            "Epoch 304/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 0.9933\n",
            "Epoch 305/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0139 - accuracy: 0.9900\n",
            "Epoch 306/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0143 - accuracy: 0.9900\n",
            "Epoch 307/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 0.9933\n",
            "Epoch 308/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 0.9933\n",
            "Epoch 309/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0135 - accuracy: 0.9933\n",
            "Epoch 310/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 0.9933\n",
            "Epoch 311/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0139 - accuracy: 0.9900\n",
            "Epoch 312/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 0.9900\n",
            "Epoch 313/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 0.9900\n",
            "Epoch 314/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0146 - accuracy: 0.9933\n",
            "Epoch 315/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 0.9933\n",
            "Epoch 316/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 0.9900\n",
            "Epoch 317/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 0.9933\n",
            "Epoch 318/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0140 - accuracy: 0.9900\n",
            "Epoch 319/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0126 - accuracy: 0.9933\n",
            "Epoch 320/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0128 - accuracy: 0.9900\n",
            "Epoch 321/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0128 - accuracy: 0.9933\n",
            "Epoch 322/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0130 - accuracy: 0.9933\n",
            "Epoch 323/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 0.9900\n",
            "Epoch 324/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 0.9933\n",
            "Epoch 325/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0125 - accuracy: 0.9933\n",
            "Epoch 326/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0129 - accuracy: 0.9933\n",
            "Epoch 327/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0152 - accuracy: 0.9933\n",
            "Epoch 328/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0129 - accuracy: 0.9933\n",
            "Epoch 329/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0122 - accuracy: 0.9933\n",
            "Epoch 330/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 0.9933\n",
            "Epoch 331/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0134 - accuracy: 0.9933\n",
            "Epoch 332/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0125 - accuracy: 0.9933\n",
            "Epoch 333/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0129 - accuracy: 0.9933\n",
            "Epoch 334/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0123 - accuracy: 0.9933\n",
            "Epoch 335/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0128 - accuracy: 0.9933\n",
            "Epoch 336/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0127 - accuracy: 0.9933\n",
            "Epoch 337/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0117 - accuracy: 0.9933\n",
            "Epoch 338/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0117 - accuracy: 0.9900\n",
            "Epoch 339/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0126 - accuracy: 0.9900\n",
            "Epoch 340/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0125 - accuracy: 0.9933\n",
            "Epoch 341/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0120 - accuracy: 0.9933\n",
            "Epoch 342/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0118 - accuracy: 0.9933\n",
            "Epoch 343/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0119 - accuracy: 0.9900\n",
            "Epoch 344/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 0.9933\n",
            "Epoch 345/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 0.9900\n",
            "Epoch 346/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0119 - accuracy: 0.9933\n",
            "Epoch 347/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0140 - accuracy: 0.9933\n",
            "Epoch 348/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0117 - accuracy: 0.9900\n",
            "Epoch 349/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0113 - accuracy: 0.9867\n",
            "Epoch 350/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 0.9900\n",
            "Epoch 351/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0111 - accuracy: 0.9933\n",
            "Epoch 352/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0112 - accuracy: 0.9933\n",
            "Epoch 353/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0110 - accuracy: 0.9933\n",
            "Epoch 354/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 0.9933\n",
            "Epoch 355/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0110 - accuracy: 0.9933\n",
            "Epoch 356/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 0.9933\n",
            "Epoch 357/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0113 - accuracy: 0.9933\n",
            "Epoch 358/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0107 - accuracy: 0.9933\n",
            "Epoch 359/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0115 - accuracy: 0.9933\n",
            "Epoch 360/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0107 - accuracy: 0.9933\n",
            "Epoch 361/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0112 - accuracy: 0.9933\n",
            "Epoch 362/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 0.9933\n",
            "Epoch 363/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0108 - accuracy: 0.9933\n",
            "Epoch 364/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0110 - accuracy: 0.9933\n",
            "Epoch 365/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0114 - accuracy: 0.9933\n",
            "Epoch 366/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0107 - accuracy: 0.9933\n",
            "Epoch 367/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0106 - accuracy: 0.9900\n",
            "Epoch 368/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0121 - accuracy: 0.9933\n",
            "Epoch 369/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0101 - accuracy: 0.9933\n",
            "Epoch 370/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 0.9933\n",
            "Epoch 371/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0104 - accuracy: 0.9933\n",
            "Epoch 372/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0115 - accuracy: 0.9933\n",
            "Epoch 373/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0100 - accuracy: 0.9933\n",
            "Epoch 374/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 0.9933\n",
            "Epoch 375/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0116 - accuracy: 0.9933\n",
            "Epoch 376/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0108 - accuracy: 0.9933\n",
            "Epoch 377/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0108 - accuracy: 0.9933\n",
            "Epoch 378/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0103 - accuracy: 0.9933\n",
            "Epoch 379/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0102 - accuracy: 0.9933\n",
            "Epoch 380/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 0.9933\n",
            "Epoch 381/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 0.9933\n",
            "Epoch 382/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0102 - accuracy: 0.9933\n",
            "Epoch 383/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0097 - accuracy: 0.9933\n",
            "Epoch 384/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 0.9933\n",
            "Epoch 385/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0097 - accuracy: 0.9933\n",
            "Epoch 386/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 0.9933\n",
            "Epoch 387/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 0.9933\n",
            "Epoch 388/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0097 - accuracy: 0.9933\n",
            "Epoch 389/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0109 - accuracy: 0.9933\n",
            "Epoch 390/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0097 - accuracy: 0.9933\n",
            "Epoch 391/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0099 - accuracy: 0.9933\n",
            "Epoch 392/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.9900\n",
            "Epoch 393/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 0.9933\n",
            "Epoch 394/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0092 - accuracy: 0.9933\n",
            "Epoch 395/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0096 - accuracy: 0.9967\n",
            "Epoch 396/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0095 - accuracy: 0.9933\n",
            "Epoch 397/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0093 - accuracy: 0.9933\n",
            "Epoch 398/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 0.9933\n",
            "Epoch 399/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0102 - accuracy: 0.9933\n",
            "Epoch 400/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0089 - accuracy: 0.9933\n",
            "Epoch 401/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0090 - accuracy: 0.9933\n",
            "Epoch 402/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0091 - accuracy: 0.9933\n",
            "Epoch 403/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0100 - accuracy: 0.9933\n",
            "Epoch 404/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 0.9933\n",
            "Epoch 405/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0089 - accuracy: 0.9933\n",
            "Epoch 406/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0088 - accuracy: 0.9933\n",
            "Epoch 407/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0106 - accuracy: 0.9933\n",
            "Epoch 408/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0091 - accuracy: 0.9933\n",
            "Epoch 409/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.9967\n",
            "Epoch 410/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0089 - accuracy: 0.9933\n",
            "Epoch 411/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0100 - accuracy: 0.9933\n",
            "Epoch 412/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0093 - accuracy: 0.9933\n",
            "Epoch 413/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0090 - accuracy: 0.9933\n",
            "Epoch 414/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 0.9933\n",
            "Epoch 415/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0090 - accuracy: 0.9933\n",
            "Epoch 416/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0101 - accuracy: 0.9967\n",
            "Epoch 417/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0090 - accuracy: 0.9933\n",
            "Epoch 418/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0092 - accuracy: 0.9933\n",
            "Epoch 419/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0085 - accuracy: 0.9933\n",
            "Epoch 420/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0085 - accuracy: 0.9933\n",
            "Epoch 421/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0088 - accuracy: 0.9967\n",
            "Epoch 422/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0086 - accuracy: 0.9933\n",
            "Epoch 423/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0096 - accuracy: 0.9933\n",
            "Epoch 424/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 0.9967\n",
            "Epoch 425/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0093 - accuracy: 0.9967\n",
            "Epoch 426/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.9967\n",
            "Epoch 427/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0081 - accuracy: 0.9933\n",
            "Epoch 428/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0094 - accuracy: 0.9933\n",
            "Epoch 429/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.9933\n",
            "Epoch 430/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0081 - accuracy: 0.9933\n",
            "Epoch 431/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.9933\n",
            "Epoch 432/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0100 - accuracy: 0.9933\n",
            "Epoch 433/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0081 - accuracy: 0.9933\n",
            "Epoch 434/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0080 - accuracy: 0.9933\n",
            "Epoch 435/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0081 - accuracy: 0.9967\n",
            "Epoch 436/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.9967\n",
            "Epoch 437/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0079 - accuracy: 0.9967\n",
            "Epoch 438/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.9933\n",
            "Epoch 439/1500\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0093 - accuracy: 0.9967\n",
            "Epoch 440/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 0.9967\n",
            "Epoch 441/1500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BihYB482A-t",
        "colab_type": "text"
      },
      "source": [
        "### Analyze and Compare\n",
        "\n",
        "**Before you Start**: You will need to install an additional library for this next segment. Install the package `mlxtend` into the environment you are using for the sprint challenge.\n",
        "\n",
        "\n",
        "The cells below generate decision boundary plots of your models (`model1` & `model2`). Review the plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNl4TMNn2A-u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "744e5db4-b401-4707-ae3b-47e79a1946c2"
      },
      "source": [
        "# Do Not change anything in this cell\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "h = .02  # step size in the mesh\n",
        "\n",
        "# create a mesh to plot in\n",
        "x_min, x_max = X[:, 0].min() - .2, X[:, 0].max() + .2\n",
        "y_min, y_max = X[:, 1].min() - .2, X[:, 1].max() + .2\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                     np.arange(y_min, y_max, h))\n",
        "\n",
        "fig = plt.figure(figsize=(12,6))\n",
        "\n",
        "\n",
        "for clf, hist, name, grd in zip([model1,model2], [h1, h2],['Perceptron', 'Multi-Layer Perceptron'],[1,2]):\n",
        "\n",
        "    ax = plt.subplot(1,2, grd)\n",
        "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
        "    title = f\"{name} with {hist.history['accuracy'][-1]:,.2f} Accuracy\"\n",
        "    plt.title(title)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/mlxtend/plotting/decision_regions.py:244: MatplotlibDeprecationWarning: Passing unsupported keyword arguments to axis() will raise a TypeError in 3.3.\n",
            "  ax.axis(xmin=xx.min(), xmax=xx.max(), y_min=yy.min(), y_max=yy.max())\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ho0_4Pi12A-z",
        "colab_type": "text"
      },
      "source": [
        "Why does the Perceptron (`model1`) only achieve ~70% accuracy? What is the architectural property of the Multi-Layer Perceptron that allows it more accurately learn the relationship between X and y? \n",
        "\n",
        "Why might this property be useful in more complex data such as images?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4lhoyBm2A-0",
        "colab_type": "text"
      },
      "source": [
        "# Your Answer Here - Change the Cell to Markdown\n",
        "\n",
        "* Q1: model1 achieves ~ 0.7 accuracy because it's a linear function because there's only one layer\n",
        "* Q2: The architectural property of the multi-layer perceptron that allows it to more accurately learn the relationship between X and y is: It allows it to compute a curve (as seen in plot for model2 above) that is able to accurately represent the relationship between X and y\n",
        "*Q3: In more complex data such as images there are many relationships between different parts of the image including lines curves and shades\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlrzRvD02A-4",
        "colab_type": "text"
      },
      "source": [
        "## 3. Keras MMP <a id=\"Q3\"></a>\n",
        "\n",
        "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
        "Use the Heart Disease Dataset (binary classification)\n",
        "Use an appropriate loss function for a binary classification task\n",
        "Use an appropriate activation function on the final layer of your network.\n",
        "Train your model using verbose output for ease of grading.\n",
        "Use GridSearchCV or RandomSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
        "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
        "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
        "You must hyperparameter tune at least 3 parameters in order to get a 3 on this section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "inputHidden": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "outputHidden": false,
        "id": "Brd5zfx32A-5",
        "colab_type": "code",
        "outputId": "f63f23d5-1390-47ac-dc09-fff18ec0b999",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
        "print(df.shape)\n",
        "df = df.sample(frac=1)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(303, 14)\n",
            "(303, 14)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>160</td>\n",
              "      <td>286</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>108</td>\n",
              "      <td>1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>120</td>\n",
              "      <td>209</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>173</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>67</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>152</td>\n",
              "      <td>277</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>130</td>\n",
              "      <td>330</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>132</td>\n",
              "      <td>1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>172</td>\n",
              "      <td>199</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>162</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     age  sex  cp  trestbps  chol  fbs  ...  exang  oldpeak  slope  ca  thal  target\n",
              "165   67    1   0       160   286    0  ...      1      1.5      1   3     2       0\n",
              "142   42    0   2       120   209    0  ...      0      0.0      1   0     2       1\n",
              "127   67    0   2       152   277    0  ...      0      0.0      2   1     2       1\n",
              "217   63    1   0       130   330    1  ...      1      1.8      2   3     3       0\n",
              "8     52    1   2       172   199    1  ...      0      0.5      2   0     3       1\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfscqOcsGC-N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "65a71239-d220-4caf-8308-e14069520ad4"
      },
      "source": [
        "#baseline\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # Compile model\n",
        "    model.compile(loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "    # create model\n",
        "model = create_model()\n",
        "\n",
        "\n",
        "                                     \n",
        "\n",
        "model.fit(X,Y, \n",
        "          epochs=3, \n",
        "          )\n",
        "scores = model.evaluate(X, Y)\n",
        "print(f\"{model.metrics_names[0]}: {scores[0]}\")\n",
        "print(f\"{model.metrics_names[1]}: {scores[1]*100}\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 16.7571 - accuracy: 0.3597\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 6.5328 - accuracy: 0.4917\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 3.3643 - accuracy: 0.6469\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 2.7511 - accuracy: 0.6898\n",
            "loss: 2.751128911972046\n",
            "accuracy: 68.97689700126648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD4Qo2Md2A--",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "outputId": "abb5e338-4cd6-492a-9c9d-bd6219dfd5ef"
      },
      "source": [
        "# Your Code Here\n",
        "import numpy\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load dataset\n",
        "\n",
        "\n",
        "dataset = df.values\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(optimizer, init_mode):\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(12, input_dim=8, activation='relu', kernel_initializer = init_mode))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # Compile model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "# define the grid search parameters\n",
        "# batch_size = [10, 20, 40, 60, 80, 100]\n",
        "# param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "# define the grid search parameters\n",
        "param_grid = {'batch_size': [10, 40, 100],\n",
        "              'epochs': [60,200,500],\n",
        "              'optimizer': ['adam', 'rmsprop'],\n",
        "              'init_mode': ['uniform', 'lecun_uniform', 'glorot_uniform']\n",
        "              #'learn_rate': [0.001, 0.01, 0.1, 0.2, 0.3],\n",
        "              #'momentum': [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
        "              }\n",
        "                                     \n",
        "\n",
        "# Create Grid Search\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
        "grid_result = grid.fit(X, Y)\n",
        "\n",
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") \n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.7789617419242859 using {'batch_size': 10, 'epochs': 200, 'init_mode': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "Means: 0.735846996307373, Stdev: 0.041365214644615254 with: {'batch_size': 10, 'epochs': 60, 'init_mode': 'uniform', 'optimizer': 'adam'}\n",
            "Means: 0.7389071106910705, Stdev: 0.06265680174054719 with: {'batch_size': 10, 'epochs': 60, 'init_mode': 'uniform', 'optimizer': 'rmsprop'}\n",
            "Means: 0.6865573763847351, Stdev: 0.09103953077820734 with: {'batch_size': 10, 'epochs': 60, 'init_mode': 'lecun_uniform', 'optimizer': 'adam'}\n",
            "Means: 0.6470491766929627, Stdev: 0.0457101156763319 with: {'batch_size': 10, 'epochs': 60, 'init_mode': 'lecun_uniform', 'optimizer': 'rmsprop'}\n",
            "Means: 0.7159016251564025, Stdev: 0.08292885940622693 with: {'batch_size': 10, 'epochs': 60, 'init_mode': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "Means: 0.6992349743843078, Stdev: 0.05992179809247221 with: {'batch_size': 10, 'epochs': 60, 'init_mode': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
            "Means: 0.756120216846466, Stdev: 0.04418992127826942 with: {'batch_size': 10, 'epochs': 200, 'init_mode': 'uniform', 'optimizer': 'adam'}\n",
            "Means: 0.722896158695221, Stdev: 0.0731559843227561 with: {'batch_size': 10, 'epochs': 200, 'init_mode': 'uniform', 'optimizer': 'rmsprop'}\n",
            "Means: 0.7656830549240112, Stdev: 0.021929933434658586 with: {'batch_size': 10, 'epochs': 200, 'init_mode': 'lecun_uniform', 'optimizer': 'adam'}\n",
            "Means: 0.6832786917686462, Stdev: 0.10519634778835604 with: {'batch_size': 10, 'epochs': 200, 'init_mode': 'lecun_uniform', 'optimizer': 'rmsprop'}\n",
            "Means: 0.7789617419242859, Stdev: 0.02806424273407721 with: {'batch_size': 10, 'epochs': 200, 'init_mode': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "Means: 0.6174863338470459, Stdev: 0.09367862804490226 with: {'batch_size': 10, 'epochs': 200, 'init_mode': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
            "Means: 0.7556830525398255, Stdev: 0.042763677901824906 with: {'batch_size': 10, 'epochs': 500, 'init_mode': 'uniform', 'optimizer': 'adam'}\n",
            "Means: 0.7488524436950683, Stdev: 0.042959089115296355 with: {'batch_size': 10, 'epochs': 500, 'init_mode': 'uniform', 'optimizer': 'rmsprop'}\n",
            "Means: 0.7260109186172485, Stdev: 0.0542844534252755 with: {'batch_size': 10, 'epochs': 500, 'init_mode': 'lecun_uniform', 'optimizer': 'adam'}\n",
            "Means: 0.6604917883872986, Stdev: 0.15808107465345728 with: {'batch_size': 10, 'epochs': 500, 'init_mode': 'lecun_uniform', 'optimizer': 'rmsprop'}\n",
            "Means: 0.775628411769867, Stdev: 0.043376205161907634 with: {'batch_size': 10, 'epochs': 500, 'init_mode': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "Means: 0.7099453568458557, Stdev: 0.05182639643784124 with: {'batch_size': 10, 'epochs': 500, 'init_mode': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
            "Means: 0.7555191278457641, Stdev: 0.04942937557018599 with: {'batch_size': 40, 'epochs': 60, 'init_mode': 'uniform', 'optimizer': 'adam'}\n",
            "Means: 0.6603278517723083, Stdev: 0.09600509999110084 with: {'batch_size': 40, 'epochs': 60, 'init_mode': 'uniform', 'optimizer': 'rmsprop'}\n",
            "Means: 0.620928955078125, Stdev: 0.07367361050463965 with: {'batch_size': 40, 'epochs': 60, 'init_mode': 'lecun_uniform', 'optimizer': 'adam'}\n",
            "Means: 0.5945901691913604, Stdev: 0.09466090412165211 with: {'batch_size': 40, 'epochs': 60, 'init_mode': 'lecun_uniform', 'optimizer': 'rmsprop'}\n",
            "Means: 0.6865573763847351, Stdev: 0.039828307564349345 with: {'batch_size': 40, 'epochs': 60, 'init_mode': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "Means: 0.696557366847992, Stdev: 0.06364036003788683 with: {'batch_size': 40, 'epochs': 60, 'init_mode': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
            "Means: 0.7422950863838196, Stdev: 0.07280164504927562 with: {'batch_size': 40, 'epochs': 200, 'init_mode': 'uniform', 'optimizer': 'adam'}\n",
            "Means: 0.6340983629226684, Stdev: 0.1760251206243129 with: {'batch_size': 40, 'epochs': 200, 'init_mode': 'uniform', 'optimizer': 'rmsprop'}\n",
            "Means: 0.7291803240776062, Stdev: 0.05052631718539848 with: {'batch_size': 40, 'epochs': 200, 'init_mode': 'lecun_uniform', 'optimizer': 'adam'}\n",
            "Means: 0.647267758846283, Stdev: 0.14532088603513393 with: {'batch_size': 40, 'epochs': 200, 'init_mode': 'lecun_uniform', 'optimizer': 'rmsprop'}\n",
            "Means: 0.7525136590003967, Stdev: 0.04972751568064249 with: {'batch_size': 40, 'epochs': 200, 'init_mode': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "Means: 0.686448085308075, Stdev: 0.07351151793938651 with: {'batch_size': 40, 'epochs': 200, 'init_mode': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
            "Means: 0.7656830549240112, Stdev: 0.012148616609881063 with: {'batch_size': 40, 'epochs': 500, 'init_mode': 'uniform', 'optimizer': 'adam'}\n",
            "Means: 0.7426775932312012, Stdev: 0.029651752753292383 with: {'batch_size': 40, 'epochs': 500, 'init_mode': 'uniform', 'optimizer': 'rmsprop'}\n",
            "Means: 0.7159562945365906, Stdev: 0.04228590414799183 with: {'batch_size': 40, 'epochs': 500, 'init_mode': 'lecun_uniform', 'optimizer': 'adam'}\n",
            "Means: 0.5940437078475952, Stdev: 0.1433078587081067 with: {'batch_size': 40, 'epochs': 500, 'init_mode': 'lecun_uniform', 'optimizer': 'rmsprop'}\n",
            "Means: 0.7456830620765686, Stdev: 0.059011947859712005 with: {'batch_size': 40, 'epochs': 500, 'init_mode': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "Means: 0.6828415274620057, Stdev: 0.04598169616364541 with: {'batch_size': 40, 'epochs': 500, 'init_mode': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
            "Means: 0.7160109281539917, Stdev: 0.03631377477853852 with: {'batch_size': 100, 'epochs': 60, 'init_mode': 'uniform', 'optimizer': 'adam'}\n",
            "Means: 0.6595081925392151, Stdev: 0.0783348755980874 with: {'batch_size': 100, 'epochs': 60, 'init_mode': 'uniform', 'optimizer': 'rmsprop'}\n",
            "Means: 0.6795628309249878, Stdev: 0.0396449441518856 with: {'batch_size': 100, 'epochs': 60, 'init_mode': 'lecun_uniform', 'optimizer': 'adam'}\n",
            "Means: 0.6175409734249115, Stdev: 0.09685648853652216 with: {'batch_size': 100, 'epochs': 60, 'init_mode': 'lecun_uniform', 'optimizer': 'rmsprop'}\n",
            "Means: 0.5152459025382996, Stdev: 0.06357904496621296 with: {'batch_size': 100, 'epochs': 60, 'init_mode': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "Means: 0.6104918003082276, Stdev: 0.1006434538261049 with: {'batch_size': 100, 'epochs': 60, 'init_mode': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
            "Means: 0.7425136566162109, Stdev: 0.05928562276249109 with: {'batch_size': 100, 'epochs': 200, 'init_mode': 'uniform', 'optimizer': 'adam'}\n",
            "Means: 0.7063387989997864, Stdev: 0.01804304653952508 with: {'batch_size': 100, 'epochs': 200, 'init_mode': 'uniform', 'optimizer': 'rmsprop'}\n",
            "Means: 0.7058469891548157, Stdev: 0.06335488177863972 with: {'batch_size': 100, 'epochs': 200, 'init_mode': 'lecun_uniform', 'optimizer': 'adam'}\n",
            "Means: 0.6995628356933594, Stdev: 0.02743234762726492 with: {'batch_size': 100, 'epochs': 200, 'init_mode': 'lecun_uniform', 'optimizer': 'rmsprop'}\n",
            "Means: 0.7259562849998474, Stdev: 0.029783169692228578 with: {'batch_size': 100, 'epochs': 200, 'init_mode': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "Means: 0.6894535541534423, Stdev: 0.05144731283993666 with: {'batch_size': 100, 'epochs': 200, 'init_mode': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
            "Means: 0.7590163946151733, Stdev: 0.031055860980752994 with: {'batch_size': 100, 'epochs': 500, 'init_mode': 'uniform', 'optimizer': 'adam'}\n",
            "Means: 0.7293989062309265, Stdev: 0.04515446981203378 with: {'batch_size': 100, 'epochs': 500, 'init_mode': 'uniform', 'optimizer': 'rmsprop'}\n",
            "Means: 0.7657923460006714, Stdev: 0.020584779229671103 with: {'batch_size': 100, 'epochs': 500, 'init_mode': 'lecun_uniform', 'optimizer': 'adam'}\n",
            "Means: 0.722295081615448, Stdev: 0.060852236810344976 with: {'batch_size': 100, 'epochs': 500, 'init_mode': 'lecun_uniform', 'optimizer': 'rmsprop'}\n",
            "Means: 0.7787978053092957, Stdev: 0.034721874028851483 with: {'batch_size': 100, 'epochs': 500, 'init_mode': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "Means: 0.7425136566162109, Stdev: 0.0251619171715391 with: {'batch_size': 100, 'epochs': 500, 'init_mode': 'glorot_uniform', 'optimizer': 'rmsprop'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7fomZBbIOqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}